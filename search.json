[
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "This is the homepage for Short Course on R Tools (SCoRT) by Dr. Mehdi Maadooliat and Dr. Hossein Haghbin. All course materials will be posted on this site.\nYou can find the course syllabus here and the course schedule here.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nMS. Teams\nTue & Thur 11:00 am - 12:15 pm\n\n\nOffice Hours\nMS. Teams\nTue & Thur 12:15 - 1:30 pm",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Short Course on R Tools - (SCoRT)",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the short course. Note that this schedule will be updated as we progress, and the timeline of topics and assignments might be updated throughout the course.\n\n\n\n\n\n\n\n\n\nWEEK\nDATE\nTOPIC\nMATERIALS\nCODE\nDUE\n\n\n\n\n1\nTue, Aug 26\n Develop your own professional R package\n📚Topic 1  📖R package\nR👩‍💻\n\n\n\n\n\n\nThu, Aug 28\nEnhance performance with Rcpp (C++)\n📚Topic 2  📖Rcpp for everyone\nR👩‍💻\n\n\n\n\n\n\nFri, Aug 29\n\n\n\n\n\n\n📝 HW 0\n\n\n2\nTue, Sep 2\n Manage and collaborate via GitHub\n📚Topic 3  📖Let’s Git started\nR👩‍💻\n\n\n\n\n\n\nThu, Sep 4\n Object-Oriented Programming (OOP) in R\n📚Topic 4  📖OOP\nR👩‍💻\n\n\n\n\n\n\nFri, Sep 5\n\n\n\n\n\n\n📝 HW 1 at 11:50 pm\n\n\n3\nTue, Sep 9\n Create dynamic Shiny web applications\n📚Topic 5  📖Shiny\nR👩‍💻\n\n\n\n\n\n\nThu, Sep 11\n Navigate the CRAN submission process\n📚Topic 6  📖Release R package\nR👩‍💻\n\n\n\n\n\n\nFri, Sep 12\n\n\n\n\n\n\n📝 HW 2 at 11:50 pm\n\n\n4\nTue, Sep 16\n Integrate Python in R using Reticulate\n📚Topic 7  📖Calling Python from R\nR👩‍💻\n\n\n\n\n\n\nThu, Sep 18\n Deep Learning in R\n📚Topic 8  📖Deep Learning with R\nR👩‍💻\n\n\n\n\n\n\nFri, Sep 19\n\n\n\n\n\n\n📝 HW 3 at 11:50 pm",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "slides/Chapter4.html#key-points",
    "href": "slides/Chapter4.html#key-points",
    "title": "Short Course on R Tools",
    "section": "Key Points",
    "text": "Key Points\n\nclass(x) order\nNextMethod()\nOverloading + inheritance via class vectors\n\n??? note Demo: create print.myclass, show dispatch.",
    "crumbs": [
      "Slides",
      "OOP in R"
    ]
  },
  {
    "objectID": "slides/Chapter6.html#description-namespace",
    "href": "slides/Chapter6.html#description-namespace",
    "title": "Short Course on R Tools",
    "section": "DESCRIPTION & NAMESPACE",
    "text": "DESCRIPTION & NAMESPACE\n\nEnsure fields: Version, URL, BugReports, License\nSemantic versioning: increment patch for minor fixes",
    "crumbs": [
      "Slides",
      "CRAN submission"
    ]
  },
  {
    "objectID": "slides/Chapter6.html#documentation-vignettes",
    "href": "slides/Chapter6.html#documentation-vignettes",
    "title": "Short Course on R Tools",
    "section": "Documentation & Vignettes",
    "text": "Documentation & Vignettes\n\nAll help files up to date\nVignettes build without errors",
    "crumbs": [
      "Slides",
      "CRAN submission"
    ]
  },
  {
    "objectID": "slides/Chapter6.html#tests-coverage",
    "href": "slides/Chapter6.html#tests-coverage",
    "title": "Short Course on R Tools",
    "section": "Tests & Coverage",
    "text": "Tests & Coverage\n\ndevtools::test() passes\nConsider covr::report()\n\n??? note Emphasize R CMD check --as-cran equivalence.",
    "crumbs": [
      "Slides",
      "CRAN submission"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site!"
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Motivating Talk\nStat Calculator\nDistribution Calculator\nRStudio\n🔗 Rfssa: An R Package for Functional SSA\n🔗 StatCalc(JAMM)\n🔗 DistCalc\n🔗 on dna\n\n\nAdvanced Texbooks\n🔗 R Package\n🔗 Advanced R by Hadley Wickham\n🔗 Quarto\n🔗 R Markdown\n🔗 ggplot2: Elegant Graphics for Data Analysis\n🔗 Fundamentals of Data Visualization\n🔗 Data Visualization: A Practical Introduction\n🔗 R for Data Science\n\n\nSome Package documentation\n🔗 devtools: devtools.r-lib.org\n🔗 Rcpp: www.rcpp.org\n🔗 GitHub: happygitwithr.com\n🔗 OOP-R6: r6.r-lib.org\n🔗 shiny: shiny.posit.co\n🔗 CRAN: cran.r-project.org\n🔗 reticulate: rstudio.github.io/reticulate\n🔗 keras: keras3.posit.co",
    "crumbs": [
      "Course information",
      "Useful links"
    ]
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "",
    "text": "Course Title: MSSC 6010: Short Course on R Tools\nMeeting Time: TuTh 2:00pm - 3:15pm\nLocation: Microsoft Teams\nWebsite: http://tinyurl.com/SCiRT",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-information",
    "href": "course-syllabus.html#course-information",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "",
    "text": "Course Title: MSSC 6010: Short Course on R Tools\nMeeting Time: TuTh 2:00pm - 3:15pm\nLocation: Microsoft Teams\nWebsite: http://tinyurl.com/SCiRT",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#instructors-details",
    "href": "course-syllabus.html#instructors-details",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Instructors Details",
    "text": "Instructors Details\n\nName: Mehdi Maadooliat, Ph.D.\nName: Hossein Haghbin, Ph.D.\nOffice Hours: Tu & Th 12:15 - 1:30pm or by e-mail",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-description",
    "href": "course-syllabus.html#course-description",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Course Description",
    "text": "Course Description\nA modern course in probability. Foundations of probability for modeling random processes with computational techniques. Topics include counting techniques, probability of events, random variables, distribution functions, probability functions, probability density functions, expectation, moments, moment generating functions, special discrete and continuous distributions, sampling distributions, transformation of variables, prior and posterior distributions, Law of Large Numbers, Central Limit Theorem, the Bayesian paradigm. Numerical and computational methods will be covered throughout topics.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#learning-outcomes",
    "href": "course-syllabus.html#learning-outcomes",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of the course, students will:\n\nUnderstand and Apply Fundamental Probability Concepts\nAnalyze and Model Random Processes\nPerform Variable Transformations\nImplement Computational Techniques\nInterpret Statistical Theorems\nCritically Evaluate Probabilistic Models\nCommunicate Probabilistic Findings",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#prerequisites",
    "href": "course-syllabus.html#prerequisites",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nThree semesters of mathematics beyond calculus and MATH 4720 or equiv.\nPreferable knowledge is MSSC 5700 and MSSC 5710.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Textbooks",
    "text": "Textbooks\n\nProbability and Statistics with R, 2nd edition by Maria Dolores Ugarte, Ana F. Militino, Alan T. Arnholt, 2016. ISBN: 9781466504394.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#grading-breakdown",
    "href": "course-syllabus.html#grading-breakdown",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Grading Breakdown",
    "text": "Grading Breakdown\n\nHomework: 30%\nProject: 10%\nMidterm Exam: 30%\nFinal Exam: 30%\n\n\nGrading Scale\n\n\n\nGrade\nRange\n\n\n\n\nA\n93.5 - 100%\n\n\nA-\n90- 93.49%\n\n\nB+\n86.5 - 89.99%\n\n\nB\n83.5 - 86.49%\n\n\nB-\n80 - 83.49%\n\n\nC+\n76.5 - 79.99%\n\n\nC\n73.5 - 76.49%\n\n\nC-\n70 - 73.49%\n\n\nD+\n66.5 - 69.99%\n\n\nD\n60 - 66.49%\n\n\nF\n&lt; 59.99%",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#exams",
    "href": "course-syllabus.html#exams",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Exams",
    "text": "Exams\nTentatively, there will be a midterm (in class) on Oct. 23rd, plus the final (in class or take home): Dec. 8th from 10:30 - 12:30pm.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#homework",
    "href": "course-syllabus.html#homework",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Homework",
    "text": "Homework\nHomework is required so that you get a better understanding of the material covered, plus it will help you to keep up. You will get a better understanding of the material if you discuss it with someone. However, you must submit YOUR OWN work to D2L website. Assignments are mostly due at 11:50pm (check for due dates in D2L).\nNO LATE HOMEWORK WILL BE ACCEPTED NOR WILL YOU BE ALLOWED TO MAKE UP MISSED HOMEWORK! Plan accordingly! It is better to submit something, even if it is incomplete. You need to type your homework (preferably using LaTeX, or Quarto) and submit it as a PDF file. Scanned homework will be graded out of 80. Low quality scanned homework will be considered as NO submission.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#make-up-policy",
    "href": "course-syllabus.html#make-up-policy",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Make-up Policy",
    "text": "Make-up Policy\nThere will not be any make-up exam or homework unless there is an emergency.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#attendance",
    "href": "course-syllabus.html#attendance",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Attendance",
    "text": "Attendance\nAttendance is required and subject to the College of Arts and Sciences policy.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#academic-honesty",
    "href": "course-syllabus.html#academic-honesty",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Academic Honesty",
    "text": "Academic Honesty\nStudents are expected to follow the University’s policy on academic honesty as outlined in the Bulletin.\nTL;DR: Don’t cheat!\nPlease abide by the following as you work on assignments in this course:\n\nCollaboration: Only work that is clearly assigned as team work should be completed collaboratively.\n\nThe homework assignments must also be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to questions (including any code) with anyone other than myself.\nFor the projects, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\nOn individual assignments you may not directly share code with another student in this class, and on team assignments you may not directly share code with another team in this class.\n\nOnline resources: I am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course’s policy is that you may make use of any online resources (e.g., StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of generative artificial intelligence (AI): You should treat generative AI, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:1 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you.\n\nYou are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask the instructor.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Important dates",
    "text": "Important dates\n\nMonday, August 25: Classes begin\nTuesday, September 2: Drop/add ends\nThursday - Friday, October 16 - 17: Fall Break\nFriday, November 14: Last day to withdraw with W\nThursday - Monday, November 26 - 30: Thanksgiving Holiday\nSaturday, December 6: Classes end\nMonday, December 8, 10:30 am - 12:30 pm: Final Exam\n\nFor more important dates, see the full MU Academic Calendar.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#important-note",
    "href": "course-syllabus.html#important-note",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Important Note",
    "text": "Important Note\nThe syllabus may be modified throughout the course. Any substantial modifications will result in a reissued syllabus.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#classical-programming-vs-machine-learning",
    "href": "slides/Chapter8.html#classical-programming-vs-machine-learning",
    "title": "Short Course on R Tools",
    "section": "Classical Programming vs Machine Learning",
    "text": "Classical Programming vs Machine Learning\n\nDeep learning is often presented as algorithms that “work like the brain”, that “think” or “understand”.\n\n\n\n\nReality is however quite far from this dream\n\n\n\n\n\nAI: the effort to automate intellectual tasks normally performed by humans.\n\n\n\n\n\n\n\n\nML: Could a computer surprise us? Rather than programmers crafting data-processing rules by hand, could a computer automatically learn these rules by looking at data? \n\n\n\n\n\n\n\n\nArtificial Intelligence\n\n\nMachine learning\n\n\nDeep learning",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#classical-programming-vs-machine-learning-1",
    "href": "slides/Chapter8.html#classical-programming-vs-machine-learning-1",
    "title": "Short Course on R Tools",
    "section": "Classical Programming vs Machine Learning",
    "text": "Classical Programming vs Machine Learning\n\nDeep learning is often presented as algorithms that “work like the brain”, that “think” or “understand”.\n\n\n \n\n\n\nAI: the effort to automate intellectual tasks normally performed by humans.\n\n\n\n\n\n\nML: Could a computer surprise us? Rather than programmers crafting data-processing rules by hand, could a computer automatically learn these rules by looking at data? \n\n\n\n\n\n\n\nArtificial Intelligence\n\n\nMachine learning\n\n\nDeep learning",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#recipes-of-a-machine-learning-algorithm",
    "href": "slides/Chapter8.html#recipes-of-a-machine-learning-algorithm",
    "title": "Short Course on R Tools",
    "section": "Recipes of a Machine Learning Algorithm",
    "text": "Recipes of a Machine Learning Algorithm\n\n\nInput data points, e.g. \n\nIf the task is speech recognition, these data points could be sound files\nIf the task is image tagging, they could be picture files\n\nExamples of the expected output \n\nIn a speech-recognition task, these could be transcripts of sound files\nIn an image task, expected outputs could tags such as “dog”, “cat”, and so on\n\nA way to measure whether the algorithm is doing a good job \n\nThis is needed to determine the distance between the output and its expected output.\nThe measurement is used as a feedback signal to adjust the way the algorithm works.",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#anatomy-of-a-neural-network",
    "href": "slides/Chapter8.html#anatomy-of-a-neural-network",
    "title": "Short Course on R Tools",
    "section": "Anatomy of a Neural Network",
    "text": "Anatomy of a Neural Network\n\n\n\n\n\nThe input data and corresponding targets \nLayers, which are combined into a network (or model) \nThe loss function, which provides feedback for learning \nThe optimizer, which determines how learning proceeds",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#lenet-5-a-pioneering-7-level-cnn",
    "href": "slides/Chapter8.html#lenet-5-a-pioneering-7-level-cnn",
    "title": "Short Course on R Tools",
    "section": "LeNet-5: a pioneering 7-level CNN",
    "text": "LeNet-5: a pioneering 7-level CNN\n\n\n\nThe first successful practical application of neural nets came in 1989 from Bell Labs, when Yann LeCun combined the earlier ideas of convolutional neural networks and backpropagation, and applied them to the problem of classifying handwritten digits.\nThe resulting network, dubbed LeNet, was used by the USPS in the 1990s to automate the reading of ZIP codes on mail envelopes.\nLeNet-5 was applied by several banks to recognize hand-written numbers on checks digitized in 32x32 pixel images.",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#why-30-years-gap",
    "href": "slides/Chapter8.html#why-30-years-gap",
    "title": "Short Course on R Tools",
    "section": "Why 30+ Years gap?",
    "text": "Why 30+ Years gap?\n\n\n\nIn 2011, Dan Ciresan from IDSIA (Switzerland) began to win academic image-classification competitions with GPU-trained deep neural networks\nin 2012, a team led by Alex Krizhevsky and advised by Geoffrey Hinton was able to achieve a top-five accuracy of 83.6%–a significant breakthrough (in 2011 it was only 74.3%). \nThree forces are driving advances in ML:\n\nHardware\nDatasets and benchmarks\nAlgorithmic advances",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#vgg16cnn-for-classification-and-detection",
    "href": "slides/Chapter8.html#vgg16cnn-for-classification-and-detection",
    "title": "Short Course on R Tools",
    "section": "VGG16–CNN for Classification and Detection",
    "text": "VGG16–CNN for Classification and Detection\n\n\n\nVGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford.\nThe model achieves 92.7% top-5 test accuracy in ImageNet. It was one of the famous model submitted to ILSVRC-2014.\nIt makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3×3 kernel-sized filters one after another.\nVGG16 was trained for weeks using NVIDIA Titan Black GPU’s.",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#neural-network-parameters---activation-func.",
    "href": "slides/Chapter8.html#neural-network-parameters---activation-func.",
    "title": "Short Course on R Tools",
    "section": "Neural Network – Parameters - Activation Func.",
    "text": "Neural Network – Parameters - Activation Func.\n\n\n\n\n\nA Neural Network\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nActivation Function",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#linear-activation-function",
    "href": "slides/Chapter8.html#linear-activation-function",
    "title": "Short Course on R Tools",
    "section": "Linear Activation function",
    "text": "Linear Activation function\n\n\n\n\n\\(Z=\\color{green}{W_1}X+\\color{lightblue}{b_1}\\)\n\n\n\n\n\n\n\n\n\\(Y=\\color{red}{W_2}Z+\\color{blue}{b_2}\\)\n\n\n\n\n\\(Y=\\color{red}{W_2}\\{\\color{green}{W_1}X+\\color{lightblue}{b_1}\\}+\\color{blue}{b_2}\\)\n\n\n\n\n\\(Y=\\{\\color{red}{W_2}\\color{green}{W_1}\\}X+\\{\\color{red}{W_2}\\color{lightblue}{b_1}+\\color{blue}{b_2}\\}\\)\n\n\n\n\n\n\n\n\n\\(Y=\\color{red}{\\mathbf{W}^*}X+\\color{blue}{\\mathbf{b}^*}\\)\n\n\n\nHidden Layers Disappears",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#what-is-tensorflow",
    "href": "slides/Chapter8.html#what-is-tensorflow",
    "title": "Short Course on R Tools",
    "section": "What is TensorFlow?",
    "text": "What is TensorFlow?\n\n\nYou define the graph in R\nGraph is compiled and optimized\nGraph is executed on devices\nNodes represent computations\nData (tensors) flows between them",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#why-tensorflow-in-r",
    "href": "slides/Chapter8.html#why-tensorflow-in-r",
    "title": "Short Course on R Tools",
    "section": "Why TensorFlow in R?",
    "text": "Why TensorFlow in R?\n\n\nHardware independent\n\nCPU (via Eigen and BLAS)\nGPU (via CUDA and cuDNN)\nTPU (Tensor Processing Unit)\n\nSupports automatic differentiation\nDistributed execution and large datasets\nVery general built-in optimization algorithms (SGD, Adam) that don’t require that all data is in RAM\nIt can be deployed with a low-latency C++ runtime\nR has a lot to offer as an interface language for TensorFlow",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#real-world-examples-of-data-tensors",
    "href": "slides/Chapter8.html#real-world-examples-of-data-tensors",
    "title": "Short Course on R Tools",
    "section": "Real-world examples of data tensors",
    "text": "Real-world examples of data tensors\n\n\n2D tensors\n\nVector data—(samples, features)  \n\n\n\n\n3D tensors\n\nGrayscale Images—(samples, height, width)\nTime-series data or sequence data—(samples, timesteps, features)\n\n\n\n\n \n\n\n\n\n\n\n4D tensors\n\nColor Images—(samples, height, width, channels)\n\n\n\n\n \n\n\n\n\n\n\n5D tensors\n\nVideo—(samples, frames, height, width, channels)",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#section-1",
    "href": "slides/Chapter8.html#section-1",
    "title": "Short Course on R Tools",
    "section": "",
    "text": "View Google Trends for TensorFlow, PyTorch, and Keras",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#installing-keras",
    "href": "slides/Chapter8.html#installing-keras",
    "title": "Short Course on R Tools",
    "section": "Installing Keras",
    "text": "Installing Keras\n  \n\n\n\n\nFirst, install the keras R package:\n\nremotes::install_github(\"rstudio/keras3\");    # OR\nInstall.packages(\"keras3\")\n\n\nTo install both the core Keras library as well as the TensorFlow backend\n\nlibrary(keras3)\nkeras3::install_keras(backend = \"tensorflow\")\n\n\n\nYou need Python installed before installing TensorFlow\n\nAnaconda (Python distribution), a free and open-source software\n\n\n\n\n\n\n\n\nYou can install TensorFlow with GPU support\n\nNVIDIA® drivers,\nCUDA Toolkit v9.0, and\ncuDNN v7.0\n\n\n\n\n\nare needed: https://tensorflow.rstudio.com/tools/local_gpu.html",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#developing-a-deep-nn-with-keras",
    "href": "slides/Chapter8.html#developing-a-deep-nn-with-keras",
    "title": "Short Course on R Tools",
    "section": "Developing a Deep NN with Keras",
    "text": "Developing a Deep NN with Keras\n  \n\n\n\n\nStep 1 - Define your training data:\n\ninput tensors and target tensors.\n\n\n\n\nStep 2 - Define a network of layers (or model)\n\nthat maps your inputs to your targets.\n\n\n\n\n\nStep 3 - Configure the learning process by choosing\n\na loss function,\nan optimizer,\nand some metrics to monitor.\n\n\n\n\n\nStep 4 - Iterate on your training data by calling the\n\nfit() method of your model.",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#keras-step-1-data-preprocessing",
    "href": "slides/Chapter8.html#keras-step-1-data-preprocessing",
    "title": "Short Course on R Tools",
    "section": "Keras: Step 1 – Data preprocessing",
    "text": "Keras: Step 1 – Data preprocessing\n  \n\n\n\n\nlibrary(keras)\n\n# Load MNIST (Modified National Institute of Standards and Technology) \nimages datasets c(c(x_train, y_train), c(x_test, y_test)) %&lt;-% dataset_mnist()\n\n# Flatten images and transform RGB values into [0,1] range \nx_train &lt;- array_reshape(x_train, c(nrow(x_train), 784))\nx_test &lt;- array_reshape(x_test, c(nrow(x_test), 784))\nx_train &lt;- x_train / 255\nx_test &lt;- x_test / 255\n\n# Convert class vectors to binary class matrices\ny_train &lt;- to_categorical(y_train, 10)\ny_test &lt;- to_categorical(y_test, 10)",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#classification-on-mnist",
    "href": "slides/Chapter8.html#classification-on-mnist",
    "title": "Short Course on R Tools",
    "section": "Classification on MNIST",
    "text": "Classification on MNIST\nmodel %&gt;% compile(\n  optimizer = 'rmsprop',\n  loss = 'categorical_crossentropy',\n  metrics = c('accuracy')\n)\nhistory &lt;- model %&gt;% fit(\n  x_train, y_train,\n  epochs = 10, batch_size = 128,\n  validation_split = 0.2\n)\n\nData preprocessing: normalization, one-hot encoding\nCallbacks: EarlyStopping, ModelCheckpoint\n\n??? note Show training curves: plot(history).",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#outline",
    "href": "slides/Chapter2.html#outline",
    "title": "Short Course on R Tools",
    "section": "Outline",
    "text": "Outline\n\n\nMotivation & Introduction\nGetting Started with cppFunction()\nUsing sourceCpp()\nData Types & Conversions\nRcpp Classes: Lists, DataFrames, Functions, Attributes\nHandling Missing Values\nStandard Template Library (STL)\nCase Studies & Benchmarks\nUsing Rcpp in Packages\nAdvanced Topics & Resources",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#lists-dataframes",
    "href": "slides/Chapter2.html#lists-dataframes",
    "title": "Short Course on R Tools",
    "section": "Lists & DataFrames",
    "text": "Lists & DataFrames\n\nList, DataFrame wrappers\nAccess with as&lt;&gt;(), .inherits(), .attr()",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#functions",
    "href": "slides/Chapter2.html#functions",
    "title": "Short Course on R Tools",
    "section": "Functions",
    "text": "Functions\n\nFunction f & RObject return type\nPositional vs named args:\n\nf(_[\"x\"] = xval, _[\"y\"] = yval);",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#attributes",
    "href": "slides/Chapter2.html#attributes",
    "title": "Short Course on R Tools",
    "section": "Attributes",
    "text": "Attributes\n\nQuery/modify with .attr() and .names()\nCreate with Vector::create()\n\n??? note Quick example: extracting residuals from lm.",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#iterators-algorithms",
    "href": "slides/Chapter2.html#iterators-algorithms",
    "title": "Short Course on R Tools",
    "section": "Iterators & Algorithms",
    "text": "Iterators & Algorithms\n\nRange-based for(const auto &x : xs)\nstd::accumulate, std::min_element, etc.",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#data-structures",
    "href": "slides/Chapter2.html#data-structures",
    "title": "Short Course on R Tools",
    "section": "Data Structures",
    "text": "Data Structures\n\nstd::vector, std::unordered_set, std::unordered_map\nEfficient growth & lookup\n\n??? note Show run-length encoding (rleC) example.",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#gibbs-sampler",
    "href": "slides/Chapter2.html#gibbs-sampler",
    "title": "Short Course on R Tools",
    "section": "Gibbs Sampler",
    "text": "Gibbs Sampler\n// [[Rcpp::export]]\nNumericMatrix gibbs_cpp(int N, int thin) { ... }\n\n~20× speedup vs R",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#agent-based-model",
    "href": "slides/Chapter2.html#agent-based-model",
    "title": "Short Course on R Tools",
    "section": "Agent-Based Model",
    "text": "Agent-Based Model\n\nR vectorisation vs Rcpp loops\nMemory overhead comparisons\n\n??? note Plot benchmark timings side-by-side.",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter1.html#description",
    "href": "slides/Chapter1.html#description",
    "title": "Short Course on R Tools",
    "section": "DESCRIPTION",
    "text": "DESCRIPTION\n\nFields: Package, Version, Title, Description, Author, Depends, Imports, Suggests, License\nSemantic versioning: major.minor.patch",
    "crumbs": [
      "Slides",
      "R package"
    ]
  },
  {
    "objectID": "slides/Chapter1.html#namespace",
    "href": "slides/Chapter1.html#namespace",
    "title": "Short Course on R Tools",
    "section": "NAMESPACE",
    "text": "NAMESPACE\n\nExport functions: export()\nImport from other packages: importFrom(dplyr, select)\nGenerate with roxygen2 or manually\n\n#' @export\nmy_function &lt;- function(x) x + 1\n??? note Emphasize keeping Imports minimal.",
    "crumbs": [
      "Slides",
      "R package"
    ]
  },
  {
    "objectID": "misc/cheatsheets.html",
    "href": "misc/cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://posit.co/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Miscellaneous",
      "Cheatsheets"
    ]
  }
]