[
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "",
    "text": "Course Title: MSSC 6010: Short Course on R Tools\nMeeting Time: TuTh 2:00pm - 3:15pm\nLocation: Microsoft Teams\nWebsite: http://tinyurl.com/SCiRT",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-information",
    "href": "course-syllabus.html#course-information",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "",
    "text": "Course Title: MSSC 6010: Short Course on R Tools\nMeeting Time: TuTh 2:00pm - 3:15pm\nLocation: Microsoft Teams\nWebsite: http://tinyurl.com/SCiRT",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#instructors-details",
    "href": "course-syllabus.html#instructors-details",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Instructors Details",
    "text": "Instructors Details\n\nName: Mehdi Maadooliat, Ph.D.\nName: Hossein Haghbin, Ph.D.\nOffice Hours: Tu & Th 12:15 - 1:30pm or by e-mail",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-description",
    "href": "course-syllabus.html#course-description",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Course Description",
    "text": "Course Description\nA modern course in probability. Foundations of probability for modeling random processes with computational techniques. Topics include counting techniques, probability of events, random variables, distribution functions, probability functions, probability density functions, expectation, moments, moment generating functions, special discrete and continuous distributions, sampling distributions, transformation of variables, prior and posterior distributions, Law of Large Numbers, Central Limit Theorem, the Bayesian paradigm. Numerical and computational methods will be covered throughout topics.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#learning-outcomes",
    "href": "course-syllabus.html#learning-outcomes",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of the course, students will:\n\nUnderstand and Apply Fundamental Probability Concepts\nAnalyze and Model Random Processes\nPerform Variable Transformations\nImplement Computational Techniques\nInterpret Statistical Theorems\nCritically Evaluate Probabilistic Models\nCommunicate Probabilistic Findings",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#prerequisites",
    "href": "course-syllabus.html#prerequisites",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nThree semesters of mathematics beyond calculus and MATH 4720 or equiv.\nPreferable knowledge is MSSC 5700 and MSSC 5710.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Textbooks",
    "text": "Textbooks\n\nProbability and Statistics with R, 2nd edition by Maria Dolores Ugarte, Ana F. Militino, Alan T. Arnholt, 2016. ISBN: 9781466504394.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#grading-breakdown",
    "href": "course-syllabus.html#grading-breakdown",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Grading Breakdown",
    "text": "Grading Breakdown\n\nHomework: 30%\nProject: 10%\nMidterm Exam: 30%\nFinal Exam: 30%\n\n\nGrading Scale\n\n\n\nGrade\nRange\n\n\n\n\nA\n93.5 - 100%\n\n\nA-\n90- 93.49%\n\n\nB+\n86.5 - 89.99%\n\n\nB\n83.5 - 86.49%\n\n\nB-\n80 - 83.49%\n\n\nC+\n76.5 - 79.99%\n\n\nC\n73.5 - 76.49%\n\n\nC-\n70 - 73.49%\n\n\nD+\n66.5 - 69.99%\n\n\nD\n60 - 66.49%\n\n\nF\n&lt; 59.99%",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#exams",
    "href": "course-syllabus.html#exams",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Exams",
    "text": "Exams\nTentatively, there will be a midterm (in class) on Oct. 23rd, plus the final (in class or take home): Dec. 8th from 10:30 - 12:30pm.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#homework",
    "href": "course-syllabus.html#homework",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Homework",
    "text": "Homework\nHomework is required so that you get a better understanding of the material covered, plus it will help you to keep up. You will get a better understanding of the material if you discuss it with someone. However, you must submit YOUR OWN work to D2L website. Assignments are mostly due at 11:50pm (check for due dates in D2L).\nNO LATE HOMEWORK WILL BE ACCEPTED NOR WILL YOU BE ALLOWED TO MAKE UP MISSED HOMEWORK! Plan accordingly! It is better to submit something, even if it is incomplete. You need to type your homework (preferably using LaTeX, or Quarto) and submit it as a PDF file. Scanned homework will be graded out of 80. Low quality scanned homework will be considered as NO submission.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#make-up-policy",
    "href": "course-syllabus.html#make-up-policy",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Make-up Policy",
    "text": "Make-up Policy\nThere will not be any make-up exam or homework unless there is an emergency.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#attendance",
    "href": "course-syllabus.html#attendance",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Attendance",
    "text": "Attendance\nAttendance is required and subject to the College of Arts and Sciences policy.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#academic-honesty",
    "href": "course-syllabus.html#academic-honesty",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Academic Honesty",
    "text": "Academic Honesty\nStudents are expected to follow the University’s policy on academic honesty as outlined in the Bulletin.\nTL;DR: Don’t cheat!\nPlease abide by the following as you work on assignments in this course:\n\nCollaboration: Only work that is clearly assigned as team work should be completed collaboratively.\n\nThe homework assignments must also be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to questions (including any code) with anyone other than myself.\nFor the projects, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\nOn individual assignments you may not directly share code with another student in this class, and on team assignments you may not directly share code with another team in this class.\n\nOnline resources: I am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course’s policy is that you may make use of any online resources (e.g., StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of generative artificial intelligence (AI): You should treat generative AI, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:1 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you.\n\nYou are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask the instructor.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Important dates",
    "text": "Important dates\n\nMonday, August 25: Classes begin\nTuesday, September 2: Drop/add ends\nThursday - Friday, October 16 - 17: Fall Break\nFriday, November 14: Last day to withdraw with W\nThursday - Monday, November 26 - 30: Thanksgiving Holiday\nSaturday, December 6: Classes end\nMonday, December 8, 10:30 am - 12:30 pm: Final Exam\n\nFor more important dates, see the full MU Academic Calendar.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#important-note",
    "href": "course-syllabus.html#important-note",
    "title": "Syllabus - Short Course on R Tools (SCoRT)",
    "section": "Important Note",
    "text": "Important Note\nThe syllabus may be modified throughout the course. Any substantial modifications will result in a reissued syllabus.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "This is the homepage for Short Course on R Tools (SCoRT) by Dr. Mehdi Maadooliat and Dr. Hossein Haghbin. All course materials will be posted on this site.\nYou can find the course syllabus here and the course schedule here.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nMS. Teams\nTue & Thur 11:00 am - 12:15 pm\n\n\nOffice Hours\nMS. Teams\nTue & Thur 12:15 - 1:30 pm",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site."
  },
  {
    "objectID": "slides/Chapter0.html#outline",
    "href": "slides/Chapter0.html#outline",
    "title": "Short Course on R Tools",
    "section": "Outline",
    "text": "Outline\n\n\nMotivation & Introduction\nGetting Started with cppFunction()\nUsing sourceCpp()\nData Types & Conversions\nRcpp Classes: Lists, DataFrames, Functions, Attributes\nHandling Missing Values\nStandard Template Library (STL)\nCase Studies & Benchmarks\nUsing Rcpp in Packages\nAdvanced Topics & Resources"
  },
  {
    "objectID": "slides/Chapter0.html#auto-animate",
    "href": "slides/Chapter0.html#auto-animate",
    "title": "Short Course on R Tools",
    "section": "Auto-Animate",
    "text": "Auto-Animate\n// Define and compile inline C++ function\n  return x - y - z;\nint add(int x, int y, int z) {\n  return x - y - z;\n  return x - y - z;\n}"
  },
  {
    "objectID": "slides/Chapter0.html#auto-animate-1",
    "href": "slides/Chapter0.html#auto-animate-1",
    "title": "Short Course on R Tools",
    "section": "Auto-Animate",
    "text": "Auto-Animate\n// Define and compile inline C++ function\nint add(int x, int y, int z) {\n  return x + y + z;\n}"
  },
  {
    "objectID": "slides/Chapter0.html#lists-dataframes",
    "href": "slides/Chapter0.html#lists-dataframes",
    "title": "Short Course on R Tools",
    "section": "Lists & DataFrames",
    "text": "Lists & DataFrames\n\nList, DataFrame wrappers\nAccess with as&lt;&gt;(), .inherits(), .attr()"
  },
  {
    "objectID": "slides/Chapter0.html#functions",
    "href": "slides/Chapter0.html#functions",
    "title": "Short Course on R Tools",
    "section": "Functions",
    "text": "Functions\n\nFunction f & RObject return type\nPositional vs named args:\nf(_[\"x\"] = xval, _[\"y\"] = yval);"
  },
  {
    "objectID": "slides/Chapter0.html#attributes",
    "href": "slides/Chapter0.html#attributes",
    "title": "Short Course on R Tools",
    "section": "Attributes",
    "text": "Attributes\n\nQuery/modify with .attr() and .names()\nCreate with Vector::create()\n\n??? note Quick example: extracting residuals from lm."
  },
  {
    "objectID": "slides/Chapter0.html#iterators-algorithms",
    "href": "slides/Chapter0.html#iterators-algorithms",
    "title": "Short Course on R Tools",
    "section": "Iterators & Algorithms",
    "text": "Iterators & Algorithms\n\nRange-based for(const auto &x : xs)\nstd::accumulate, std::min_element, etc."
  },
  {
    "objectID": "slides/Chapter0.html#data-structures",
    "href": "slides/Chapter0.html#data-structures",
    "title": "Short Course on R Tools",
    "section": "Data Structures",
    "text": "Data Structures\n\nstd::vector, std::unordered_set, std::unordered_map\nEfficient growth & lookup\n\n??? note Show run-length encoding (rleC) example."
  },
  {
    "objectID": "slides/Chapter0.html#gibbs-sampler",
    "href": "slides/Chapter0.html#gibbs-sampler",
    "title": "Short Course on R Tools",
    "section": "Gibbs Sampler",
    "text": "Gibbs Sampler\n// [[Rcpp::export]]\nNumericMatrix gibbs_cpp(int N, int thin) { ... }\n\n~20× speedup vs R"
  },
  {
    "objectID": "slides/Chapter0.html#agent-based-model",
    "href": "slides/Chapter0.html#agent-based-model",
    "title": "Short Course on R Tools",
    "section": "Agent-Based Model",
    "text": "Agent-Based Model\n\nR vectorisation vs Rcpp loops\nMemory overhead comparisons\n\n??? note Plot benchmark timings side-by-side."
  },
  {
    "objectID": "slides/Chapter2.html#outline",
    "href": "slides/Chapter2.html#outline",
    "title": "Short Course on R Tools",
    "section": "Outline",
    "text": "Outline\n\n\nMotivation & Introduction\nGetting Started with cppFunction()\nUsing sourceCpp()\nData Types & Conversions\nRcpp Classes: Lists, DataFrames, Functions, Attributes\nHandling Missing Values\nStandard Template Library (STL)\nCase Studies & Benchmarks\nUsing Rcpp in Packages\nAdvanced Topics & Resources",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#lists-dataframes",
    "href": "slides/Chapter2.html#lists-dataframes",
    "title": "Short Course on R Tools",
    "section": "Lists & DataFrames",
    "text": "Lists & DataFrames\n\nList, DataFrame wrappers\nAccess with as&lt;&gt;(), .inherits(), .attr()",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#functions",
    "href": "slides/Chapter2.html#functions",
    "title": "Short Course on R Tools",
    "section": "Functions",
    "text": "Functions\n\nFunction f & RObject return type\nPositional vs named args:\n\nf(_[\"x\"] = xval, _[\"y\"] = yval);",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#attributes",
    "href": "slides/Chapter2.html#attributes",
    "title": "Short Course on R Tools",
    "section": "Attributes",
    "text": "Attributes\n\nQuery/modify with .attr() and .names()\nCreate with Vector::create()\n\n??? note Quick example: extracting residuals from lm.",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#iterators-algorithms",
    "href": "slides/Chapter2.html#iterators-algorithms",
    "title": "Short Course on R Tools",
    "section": "Iterators & Algorithms",
    "text": "Iterators & Algorithms\n\nRange-based for(const auto &x : xs)\nstd::accumulate, std::min_element, etc.",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#data-structures",
    "href": "slides/Chapter2.html#data-structures",
    "title": "Short Course on R Tools",
    "section": "Data Structures",
    "text": "Data Structures\n\nstd::vector, std::unordered_set, std::unordered_map\nEfficient growth & lookup\n\n??? note Show run-length encoding (rleC) example.",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#gibbs-sampler",
    "href": "slides/Chapter2.html#gibbs-sampler",
    "title": "Short Course on R Tools",
    "section": "Gibbs Sampler",
    "text": "Gibbs Sampler\n// [[Rcpp::export]]\nNumericMatrix gibbs_cpp(int N, int thin) { ... }\n\n~20× speedup vs R",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter2.html#agent-based-model",
    "href": "slides/Chapter2.html#agent-based-model",
    "title": "Short Course on R Tools",
    "section": "Agent-Based Model",
    "text": "Agent-Based Model\n\nR vectorisation vs Rcpp loops\nMemory overhead comparisons\n\n??? note Plot benchmark timings side-by-side.",
    "crumbs": [
      "Slides",
      "RCpp"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#classical-programming-vs-machine-learning",
    "href": "slides/Chapter8.html#classical-programming-vs-machine-learning",
    "title": "Short Course on R Tools",
    "section": "Classical Programming vs Machine Learning",
    "text": "Classical Programming vs Machine Learning\n\nDeep learning is often presented as algorithms that “work like the brain”, that “think” or “understand”.\n\n\n\n\nReality is however quite far from this dream\n\n\n\n\n\nAI: the effort to automate intellectual tasks normally performed by humans.\n\n\n\n\n\n\n\n\nML: Could a computer surprise us? Rather than programmers crafting data-processing rules by hand, could a computer automatically learn these rules by looking at data? \n\n\n\n\n\n\n\n\nArtificial Intelligence\n\n\nMachine learning\n\n\nDeep learning",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#classical-programming-vs-machine-learning-1",
    "href": "slides/Chapter8.html#classical-programming-vs-machine-learning-1",
    "title": "Short Course on R Tools",
    "section": "Classical Programming vs Machine Learning",
    "text": "Classical Programming vs Machine Learning\n\nDeep learning is often presented as algorithms that “work like the brain”, that “think” or “understand”.\n\n\n \n\n\n\nAI: the effort to automate intellectual tasks normally performed by humans.\n\n\n\n\n\n\nML: Could a computer surprise us? Rather than programmers crafting data-processing rules by hand, could a computer automatically learn these rules by looking at data? \n\n\n\n\n\n\n\nArtificial Intelligence\n\n\nMachine learning\n\n\nDeep learning",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#recipes-of-a-machine-learning-algorithm",
    "href": "slides/Chapter8.html#recipes-of-a-machine-learning-algorithm",
    "title": "Short Course on R Tools",
    "section": "Recipes of a Machine Learning Algorithm",
    "text": "Recipes of a Machine Learning Algorithm\n\n\nInput data points, e.g. \n\nIf the task is speech recognition, these data points could be sound files\nIf the task is image tagging, they could be picture files\n\nExamples of the expected output \n\nIn a speech-recognition task, these could be transcripts of sound files\nIn an image task, expected outputs could tags such as “dog”, “cat”, and so on\n\nA way to measure whether the algorithm is doing a good job \n\nThis is needed to determine the distance between the output and its expected output.\nThe measurement is used as a feedback signal to adjust the way the algorithm works.",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#anatomy-of-a-neural-network",
    "href": "slides/Chapter8.html#anatomy-of-a-neural-network",
    "title": "Short Course on R Tools",
    "section": "Anatomy of a Neural Network",
    "text": "Anatomy of a Neural Network\n\n\n\n\n\nThe input data and corresponding targets \nLayers, which are combined into a network (or model) \nThe loss function, which provides feedback for learning \nThe optimizer, which determines how learning proceeds",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#lenet-5-a-pioneering-7-level-cnn",
    "href": "slides/Chapter8.html#lenet-5-a-pioneering-7-level-cnn",
    "title": "Short Course on R Tools",
    "section": "LeNet-5: a pioneering 7-level CNN",
    "text": "LeNet-5: a pioneering 7-level CNN\n\n\n\nThe first successful practical application of neural nets came in 1989 from Bell Labs, when Yann LeCun combined the earlier ideas of convolutional neural networks and backpropagation, and applied them to the problem of classifying handwritten digits.\nThe resulting network, dubbed LeNet, was used by the USPS in the 1990s to automate the reading of ZIP codes on mail envelopes.\nLeNet-5 was applied by several banks to recognize hand-written numbers on checks digitized in 32x32 pixel images.",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#why-30-years-gap",
    "href": "slides/Chapter8.html#why-30-years-gap",
    "title": "Short Course on R Tools",
    "section": "Why 30+ Years gap?",
    "text": "Why 30+ Years gap?\n\n\n\nIn 2011, Dan Ciresan from IDSIA (Switzerland) began to win academic image-classification competitions with GPU-trained deep neural networks\nin 2012, a team led by Alex Krizhevsky and advised by Geoffrey Hinton was able to achieve a top-five accuracy of 83.6%–a significant breakthrough (in 2011 it was only 74.3%). \nThree forces are driving advances in ML:\n\nHardware\nDatasets and benchmarks\nAlgorithmic advances",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#vgg16cnn-for-classification-and-detection",
    "href": "slides/Chapter8.html#vgg16cnn-for-classification-and-detection",
    "title": "Short Course on R Tools",
    "section": "VGG16–CNN for Classification and Detection",
    "text": "VGG16–CNN for Classification and Detection\n\n\n\nVGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford.\nThe model achieves 92.7% top-5 test accuracy in ImageNet. It was one of the famous model submitted to ILSVRC-2014.\nIt makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3×3 kernel-sized filters one after another.\nVGG16 was trained for weeks using NVIDIA Titan Black GPU’s.",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#neural-network-parameters---activation-func.",
    "href": "slides/Chapter8.html#neural-network-parameters---activation-func.",
    "title": "Short Course on R Tools",
    "section": "Neural Network – Parameters - Activation Func.",
    "text": "Neural Network – Parameters - Activation Func.\n\n\n\n\n\nA Neural Network\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nActivation Function",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#linear-activation-function",
    "href": "slides/Chapter8.html#linear-activation-function",
    "title": "Short Course on R Tools",
    "section": "Linear Activation function",
    "text": "Linear Activation function\n\n\n\n\n\\(Z=\\color{green}{W_1}X+\\color{lightblue}{b_1}\\)\n\n\n\n\n\n\n\n\n\\(Y=\\color{red}{W_2}Z+\\color{blue}{b_2}\\)\n\n\n\n\n\\(Y=\\color{red}{W_2}\\{\\color{green}{W_1}X+\\color{lightblue}{b_1}\\}+\\color{blue}{b_2}\\)\n\n\n\n\n\\(Y=\\{\\color{red}{W_2}\\color{green}{W_1}\\}X+\\{\\color{red}{W_2}\\color{lightblue}{b_1}+\\color{blue}{b_2}\\}\\)\n\n\n\n\n\n\n\n\n\\(Y=\\color{red}{\\mathbf{W}^*}X+\\color{blue}{\\mathbf{b}^*}\\)\n\n\n\nHidden Layers Disappears",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#what-is-tensorflow",
    "href": "slides/Chapter8.html#what-is-tensorflow",
    "title": "Short Course on R Tools",
    "section": "What is TensorFlow?",
    "text": "What is TensorFlow?\n\n\nYou define the graph in R\nGraph is compiled and optimized\nGraph is executed on devices\nNodes represent computations\nData (tensors) flows between them",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#why-tensorflow-in-r",
    "href": "slides/Chapter8.html#why-tensorflow-in-r",
    "title": "Short Course on R Tools",
    "section": "Why TensorFlow in R?",
    "text": "Why TensorFlow in R?\n\n\nHardware independent\n\nCPU (via Eigen and BLAS)\nGPU (via CUDA and cuDNN)\nTPU (Tensor Processing Unit)\n\nSupports automatic differentiation\nDistributed execution and large datasets\nVery general built-in optimization algorithms (SGD, Adam) that don’t require that all data is in RAM\nIt can be deployed with a low-latency C++ runtime\nR has a lot to offer as an interface language for TensorFlow",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#real-world-examples-of-data-tensors",
    "href": "slides/Chapter8.html#real-world-examples-of-data-tensors",
    "title": "Short Course on R Tools",
    "section": "Real-world examples of data tensors",
    "text": "Real-world examples of data tensors\n\n\n2D tensors\n\nVector data—(samples, features)  \n\n\n\n\n3D tensors\n\nGrayscale Images—(samples, height, width)\nTime-series data or sequence data—(samples, timesteps, features)\n\n\n\n\n \n\n\n\n\n\n\n4D tensors\n\nColor Images—(samples, height, width, channels)\n\n\n\n\n \n\n\n\n\n\n\n5D tensors\n\nVideo—(samples, frames, height, width, channels)",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#installing-keras",
    "href": "slides/Chapter8.html#installing-keras",
    "title": "Short Course on R Tools",
    "section": "Installing Keras",
    "text": "Installing Keras\n  \n\n\n\n\nFirst, install the keras R package:\n\nremotes::install_github(\"rstudio/keras3\");    # OR\nInstall.packages(\"keras3\")\n\n\nTo install both the core Keras library as well as the TensorFlow backend\n\nlibrary(keras3)\nkeras3::install_keras(backend = \"tensorflow\")\n\n\n\nYou need Python installed before installing TensorFlow\n\nAnaconda (Python distribution), a free and open-source software\n\n\n\n\n\n\n\n\nYou can install TensorFlow with GPU support\n\nNVIDIA® drivers,\nCUDA Toolkit v9.0, and\ncuDNN v7.0\n\n\n\n\n\nare needed: https://tensorflow.rstudio.com/tools/local_gpu.html",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#developing-a-deep-nn-with-keras",
    "href": "slides/Chapter8.html#developing-a-deep-nn-with-keras",
    "title": "Short Course on R Tools",
    "section": "Developing a Deep NN with Keras",
    "text": "Developing a Deep NN with Keras\n  \n\n\n\n\nStep 1 - Define your training data:\n\ninput tensors and target tensors.\n\n\n\n\nStep 2 - Define a network of layers (or model)\n\nthat maps your inputs to your targets.\n\n\n\n\n\nStep 3 - Configure the learning process by choosing\n\na loss function,\nan optimizer,\nand some metrics to monitor.\n\n\n\n\n\nStep 4 - Iterate on your training data by calling the\n\nfit() method of your model.",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#keras-step-1-data-preprocessing",
    "href": "slides/Chapter8.html#keras-step-1-data-preprocessing",
    "title": "Short Course on R Tools",
    "section": "Keras: Step 1 – Data preprocessing",
    "text": "Keras: Step 1 – Data preprocessing\n  \n\n\n\n\nlibrary(keras)\n\n# Load MNIST (Modified National Institute of Standards and Technology) \nimages datasets c(c(x_train, y_train), c(x_test, y_test)) %&lt;-% dataset_mnist()\n\n# Flatten images and transform RGB values into [0,1] range \nx_train &lt;- array_reshape(x_train, c(nrow(x_train), 784))\nx_test &lt;- array_reshape(x_test, c(nrow(x_test), 784))\nx_train &lt;- x_train / 255\nx_test &lt;- x_test / 255\n\n# Convert class vectors to binary class matrices\ny_train &lt;- to_categorical(y_train, 10)\ny_test &lt;- to_categorical(y_test, 10)",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter8.html#classification-on-mnist",
    "href": "slides/Chapter8.html#classification-on-mnist",
    "title": "Short Course on R Tools",
    "section": "Classification on MNIST",
    "text": "Classification on MNIST\nmodel %&gt;% compile(\n  optimizer = 'rmsprop',\n  loss = 'categorical_crossentropy',\n  metrics = c('accuracy')\n)\nhistory &lt;- model %&gt;% fit(\n  x_train, y_train,\n  epochs = 10, batch_size = 128,\n  validation_split = 0.2\n)\n\nData preprocessing: normalization, one-hot encoding\nCallbacks: EarlyStopping, ModelCheckpoint\n\n??? note Show training curves: plot(history).",
    "crumbs": [
      "Slides",
      "Deep Learning in R"
    ]
  },
  {
    "objectID": "slides/Chapter3.html#sampling-from-a-finite-population",
    "href": "slides/Chapter3.html#sampling-from-a-finite-population",
    "title": "Short Course on R Tools",
    "section": "Sampling from a Finite Population",
    "text": "Sampling from a Finite Population\n\nIntroduction to finite population sampling\nExample: Tossing coins, choosing lottery numbers\n\n\n# Sampling examples\nsample(0:1, size = 10, replace = TRUE)  # Tossing coins\n\n [1] 1 1 0 1 0 0 0 1 0 0\n\nsample(1:100, size = 6, replace = FALSE)  # Choosing lottery numbers\n\n[1] 65 81 92 96 45 94\n\nsample(letters)  # Permutation of letters\n\n [1] \"m\" \"w\" \"n\" \"b\" \"g\" \"s\" \"l\" \"a\" \"u\" \"e\" \"f\" \"c\" \"t\" \"k\" \"o\" \"r\" \"p\" \"x\" \"j\"\n[20] \"v\" \"i\" \"q\" \"d\" \"h\" \"z\" \"y\"",
    "crumbs": [
      "Slides",
      "GitHub"
    ]
  },
  {
    "objectID": "slides/Chapter3.html#multinomial-distribution",
    "href": "slides/Chapter3.html#multinomial-distribution",
    "title": "Short Course on R Tools",
    "section": "Multinomial Distribution",
    "text": "Multinomial Distribution\n\nIntroduction to multinomial distribution\nExample: Sampling from a multinomial distribution\n\n\n# Sample from multinomial distribution\nx &lt;- sample(1:3, size = 100, replace = TRUE, prob = c(.2, .3, .5))\ntable(x)\n\nx\n 1  2  3 \n23 29 48",
    "crumbs": [
      "Slides",
      "GitHub"
    ]
  },
  {
    "objectID": "slides/Chapter3.html#continuous-case",
    "href": "slides/Chapter3.html#continuous-case",
    "title": "Short Course on R Tools",
    "section": "Continuous Case",
    "text": "Continuous Case\n\nExplanation of the inverse transform method for continuous distributions\nExample: Simulating exponential random variables\n\n\n# Inverse transform method for exponential distribution\nn &lt;- 1000\nU &lt;- runif(n)\nX &lt;- -log(1 - U)\nhist(X, main=\"Exponential Distribution via Inverse Transform\", col=\"lightblue\")",
    "crumbs": [
      "Slides",
      "GitHub"
    ]
  },
  {
    "objectID": "slides/Chapter3.html#discrete-case",
    "href": "slides/Chapter3.html#discrete-case",
    "title": "Short Course on R Tools",
    "section": "Discrete Case",
    "text": "Discrete Case\n\nExample of applying the inverse transform method to discrete random variables\n\n\n# Inverse transform method for geometric distribution\np &lt;- 0.5\nX_geom &lt;- ceiling(log(1 - runif(n)) / log(1 - p))\nhist(X_geom, main=\"Geometric Distribution via Inverse Transform\", col=\"lightgreen\")",
    "crumbs": [
      "Slides",
      "GitHub"
    ]
  },
  {
    "objectID": "slides/Chapter3.html#introduction-to-acceptance-rejection-method",
    "href": "slides/Chapter3.html#introduction-to-acceptance-rejection-method",
    "title": "Short Course on R Tools",
    "section": "Introduction to Acceptance-Rejection Method",
    "text": "Introduction to Acceptance-Rejection Method\n\nExplanation of the acceptance-rejection method\nExample: Sampling from a target distribution\n\n\n# Acceptance-rejection method example\ntarget &lt;- function(x) { ifelse(x &gt; 0, exp(-x), 0) }\nproposal &lt;- function(x) { dnorm(x, mean = 2, sd = 1) }\n\nX &lt;- rnorm(1000, mean = 2, sd = 1)\naccept &lt;- runif(1000) &lt; target(X) / (1.5 * proposal(X))\n\nhist(X[accept], main=\"Accepted Samples from Target Distribution\", col=\"lightcoral\")",
    "crumbs": [
      "Slides",
      "GitHub"
    ]
  },
  {
    "objectID": "slides/Chapter3.html#transformation-of-random-variables",
    "href": "slides/Chapter3.html#transformation-of-random-variables",
    "title": "Short Course on R Tools",
    "section": "Transformation of Random Variables",
    "text": "Transformation of Random Variables\n\nIntroduction to transformation methods\nExample: Box-Muller transform for generating normal random variables\n\n\n# Box-Muller transform\nn &lt;- 1000\nU1 &lt;- runif(n)\nU2 &lt;- runif(n)\nZ1 &lt;- sqrt(-2 * log(U1)) * cos(2 * pi * U2)\nZ2 &lt;- sqrt(-2 * log(U1)) * sin(2 * pi * U2)\nhist(Z1, main=\"Normal Distribution via Box-Muller\", col=\"lightblue\")",
    "crumbs": [
      "Slides",
      "GitHub"
    ]
  },
  {
    "objectID": "slides/Chapter3.html#sums-and-mixtures",
    "href": "slides/Chapter3.html#sums-and-mixtures",
    "title": "Short Course on R Tools",
    "section": "Sums and Mixtures",
    "text": "Sums and Mixtures\n\nExplanation of sums and mixtures of random variables\nExample: Mixture of normals\n\n\n# Mixture of normals\nlibrary(MASS)\nmu1 &lt;- 0; mu2 &lt;- 3; sigma1 &lt;- 1; sigma2 &lt;- 2\np &lt;- 0.3\nX &lt;- ifelse(runif(n) &lt; p, rnorm(n, mu1, sigma1), rnorm(n, mu2, sigma2))\nhist(X, main=\"Mixture of Normal Distributions\", col=\"lightgreen\")",
    "crumbs": [
      "Slides",
      "GitHub"
    ]
  },
  {
    "objectID": "slides/Chapter7.html#basic-monte-carlo-estimation",
    "href": "slides/Chapter7.html#basic-monte-carlo-estimation",
    "title": "Short Course on R Tools",
    "section": "Basic Monte Carlo Estimation",
    "text": "Basic Monte Carlo Estimation\n\nIntroduction to Monte Carlo estimation\nExample: Estimating the expected difference of two normal variables\n\n\nm &lt;- 1000\ng &lt;- numeric(m)\nfor (i in 1:m) {\n    x &lt;- rnorm(2)\n    g[i] &lt;- abs(x[1] - x[2])\n}\nest &lt;- mean(g)\nest\n\n[1] 1.106403",
    "crumbs": [
      "Slides",
      "Python in R"
    ]
  },
  {
    "objectID": "slides/Chapter7.html#visualizing-monte-carlo-simulations",
    "href": "slides/Chapter7.html#visualizing-monte-carlo-simulations",
    "title": "Short Course on R Tools",
    "section": "Visualizing Monte Carlo Simulations",
    "text": "Visualizing Monte Carlo Simulations\n\n# Histogram of the simulated differences\nhist(g, main=\"Histogram of Differences (Monte Carlo)\", col=\"lightblue\")",
    "crumbs": [
      "Slides",
      "Python in R"
    ]
  },
  {
    "objectID": "slides/Chapter7.html#estimating-the-mean-squared-error-mse",
    "href": "slides/Chapter7.html#estimating-the-mean-squared-error-mse",
    "title": "Short Course on R Tools",
    "section": "Estimating the Mean Squared Error (MSE)",
    "text": "Estimating the Mean Squared Error (MSE)\n\nMonte Carlo estimation of MSE for trimmed means\n\n\nn &lt;- 20\nm &lt;- 1000\nmean_trim &lt;- numeric(m)\nfor (i in 1:m) {\n    x &lt;- rnorm(n)\n    mean_trim[i] &lt;- mean(x, trim = 0.1)\n}\nmse &lt;- mean((mean_trim - 0)^2)\nmse\n\n[1] 0.05121705",
    "crumbs": [
      "Slides",
      "Python in R"
    ]
  },
  {
    "objectID": "slides/Chapter7.html#visualizing-mse-simulations",
    "href": "slides/Chapter7.html#visualizing-mse-simulations",
    "title": "Short Course on R Tools",
    "section": "Visualizing MSE Simulations",
    "text": "Visualizing MSE Simulations\n\n# Histogram of the trimmed means\nhist(mean_trim, main=\"Trimmed Means (Monte Carlo MSE)\", col=\"lightgreen\")",
    "crumbs": [
      "Slides",
      "Python in R"
    ]
  },
  {
    "objectID": "slides/Chapter7.html#additional-monte-carlo-techniques",
    "href": "slides/Chapter7.html#additional-monte-carlo-techniques",
    "title": "Short Course on R Tools",
    "section": "Additional Monte Carlo Techniques",
    "text": "Additional Monte Carlo Techniques\n\nExploring advanced Monte Carlo techniques for inference\nExample: Hypothesis testing with Monte Carlo methods\n\n\n# Monte Carlo test example: Hypothesis testing\nn &lt;- 50\nm &lt;- 1000\ntest_stat &lt;- numeric(m)\nfor (i in 1:m) {\n    x &lt;- rnorm(n)\n    test_stat[i] &lt;- mean(x)\n}\np_value &lt;- mean(test_stat &gt;= 1.96)\np_value\n\n[1] 0",
    "crumbs": [
      "Slides",
      "Python in R"
    ]
  },
  {
    "objectID": "slides/Chapter7.html#conclusion",
    "href": "slides/Chapter7.html#conclusion",
    "title": "Short Course on R Tools",
    "section": "Conclusion",
    "text": "Conclusion\n\nRecap of Monte Carlo methods in inference, MSE estimation, and hypothesis testing\nPractice: Apply these methods to other inferential problems\n\n\n\n\n\n🔗 tinyurl.com/SCiRT",
    "crumbs": [
      "Slides",
      "Python in R"
    ]
  },
  {
    "objectID": "slides/Chapter1.html#probability-distributions",
    "href": "slides/Chapter1.html#probability-distributions",
    "title": "Short Course on R Tools",
    "section": "Probability Distributions",
    "text": "Probability Distributions\n\ndnorm(), pnorm(), qnorm()\nExploring statistical tests in R",
    "crumbs": [
      "Slides",
      "R package"
    ]
  },
  {
    "objectID": "slides/Chapter1.html#statistical-tests",
    "href": "slides/Chapter1.html#statistical-tests",
    "title": "Short Course on R Tools",
    "section": "Statistical Tests",
    "text": "Statistical Tests\n\nt.test(), chisq.test()",
    "crumbs": [
      "Slides",
      "R package"
    ]
  },
  {
    "objectID": "slides/Chapter1.html#defining-functions",
    "href": "slides/Chapter1.html#defining-functions",
    "title": "Short Course on R Tools",
    "section": "Defining Functions",
    "text": "Defining Functions\n\nfunction(arglist) expr\nReturn values and default arguments\n\n\nsumdice &lt;- function(n) {\n  k &lt;- sample(1:6, size=n, replace=TRUE)\n  return(sum(k))\n}\nsumdice(2)\n\n[1] 8",
    "crumbs": [
      "Slides",
      "R package"
    ]
  },
  {
    "objectID": "slides/Chapter1.html#data-structures-in-r",
    "href": "slides/Chapter1.html#data-structures-in-r",
    "title": "Short Course on R Tools",
    "section": "Data Structures in R",
    "text": "Data Structures in R\n\nArrays, matrices, and data frames\n\n\n# Creating vectors and matrices\nx &lt;- c(1, 2, 3, 4)\nmatrix_x &lt;- matrix(x, nrow=2, ncol=2)\nprint(matrix_x)\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n\n\nExample: Iris data set\n\n\ndata(iris)\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50",
    "crumbs": [
      "Slides",
      "R package"
    ]
  },
  {
    "objectID": "slides/Chapter1.html#basic-plots",
    "href": "slides/Chapter1.html#basic-plots",
    "title": "Short Course on R Tools",
    "section": "Basic Plots",
    "text": "Basic Plots\n\nplot(), hist(), boxplot()\n\n\nCodePlot\n\n\n\npar(mfrow = c(1, 3))\n#boxplot(iris)\n#hist(iris[,1])\nplot(iris)",
    "crumbs": [
      "Slides",
      "R package"
    ]
  },
  {
    "objectID": "slides/Chapter1.html#introduction-to-ggplot2",
    "href": "slides/Chapter1.html#introduction-to-ggplot2",
    "title": "Short Course on R Tools",
    "section": "Introduction to ggplot2",
    "text": "Introduction to ggplot2\n\nVisualizing using ggplot2\n\n\nCodePlot\n\n\n\nlibrary(ggplot2)\nggplot(iris, aes(x=Sepal.Length, y=Petal.Length)) + \n  geom_point() + \n  geom_smooth(method=\"lm\", se=FALSE, color=\"blue\") + \n  theme_minimal() + \n  labs(title=\"Sepal vs Petal Length in Iris Dataset\", x=\"Sepal Length\", y=\"Petal Length\")",
    "crumbs": [
      "Slides",
      "R package"
    ]
  },
  {
    "objectID": "slides/Chapter1.html#managing-files",
    "href": "slides/Chapter1.html#managing-files",
    "title": "Short Course on R Tools",
    "section": "Managing Files",
    "text": "Managing Files\n\nWorking directories and file input/output\nUsing scripts and automation",
    "crumbs": [
      "Slides",
      "R package"
    ]
  },
  {
    "objectID": "slides/Chapter1.html#dynamic-documents",
    "href": "slides/Chapter1.html#dynamic-documents",
    "title": "Short Course on R Tools",
    "section": "Dynamic Documents",
    "text": "Dynamic Documents\n\nCreating reports with R Markdown\nIntroduction to knitr package",
    "crumbs": [
      "Slides",
      "R package"
    ]
  },
  {
    "objectID": "slides/Chapter6.html#introduction-to-monte-carlo-integration",
    "href": "slides/Chapter6.html#introduction-to-monte-carlo-integration",
    "title": "Short Course on R Tools",
    "section": "Introduction to Monte Carlo Integration",
    "text": "Introduction to Monte Carlo Integration\n\nBasic concepts of Monte Carlo integration\nExample: Integrating using uniform distribution\n\n\nm &lt;- 10000\nx &lt;- runif(m)\ntheta.hat &lt;- mean(exp(-x))\ntheta.hat\n\n[1] 0.6324893\n\n1 - exp(-1)\n\n[1] 0.6321206",
    "crumbs": [
      "Slides",
      "CRAN submission"
    ]
  },
  {
    "objectID": "slides/Chapter6.html#example-monte-carlo-integration-with-bounded-intervals",
    "href": "slides/Chapter6.html#example-monte-carlo-integration-with-bounded-intervals",
    "title": "Short Course on R Tools",
    "section": "Example: Monte Carlo integration with bounded intervals",
    "text": "Example: Monte Carlo integration with bounded intervals\n\nm &lt;- 10000\nx &lt;- runif(m, min=2, max=4)\ntheta.hat &lt;- mean(exp(-x)) * 2\ntheta.hat\n\n[1] 0.1171577\n\nexp(-2) - exp(-4)\n\n[1] 0.1170196",
    "crumbs": [
      "Slides",
      "CRAN submission"
    ]
  },
  {
    "objectID": "slides/Chapter6.html#unbounded-intervals",
    "href": "slides/Chapter6.html#unbounded-intervals",
    "title": "Short Course on R Tools",
    "section": "Unbounded Intervals",
    "text": "Unbounded Intervals\n\nHandling unbounded intervals in Monte Carlo integration\n\n\n# Plotting a function over an unbounded interval\nx &lt;- seq(.1, 2.5, length.out = 100)\ny &lt;- exp(-x^2 / 2)\nplot(x, y, type=\"l\", main=\"Function Plot for Unbounded Interval\", col=\"blue\")",
    "crumbs": [
      "Slides",
      "CRAN submission"
    ]
  },
  {
    "objectID": "slides/Chapter6.html#introduction-to-importance-sampling",
    "href": "slides/Chapter6.html#introduction-to-importance-sampling",
    "title": "Short Course on R Tools",
    "section": "Introduction to Importance Sampling",
    "text": "Introduction to Importance Sampling\n\nImportance sampling and its applications\nExample: Applying importance sampling\n\n\n# Example of importance sampling\ng &lt;- function(x) exp(-x^2 / 2)\nf &lt;- function(x) dnorm(x, mean = 1)\nx &lt;- rnorm(10000, mean = 1)\ntheta.hat &lt;- mean(g(x) / f(x))\ntheta.hat\n\n[1] 2.558609",
    "crumbs": [
      "Slides",
      "CRAN submission"
    ]
  },
  {
    "objectID": "slides/Chapter6.html#visualizing-importance-sampling",
    "href": "slides/Chapter6.html#visualizing-importance-sampling",
    "title": "Short Course on R Tools",
    "section": "Visualizing Importance Sampling",
    "text": "Visualizing Importance Sampling\n\n# Compare the original function with the importance sampling function\ncurve(g, from = -3, to = 3, col = \"blue\", lwd = 2, main=\"Importance Sampling: g(x) vs f(x)\")\ncurve(f, add = TRUE, col = \"red\", lty = 2, lwd = 2)\nlegend(\"topright\", legend=c(\"g(x)\", \"f(x)\"), col=c(\"blue\", \"red\"), lty=c(1, 2), lwd=2)",
    "crumbs": [
      "Slides",
      "CRAN submission"
    ]
  },
  {
    "objectID": "slides/Chapter6.html#control-variates",
    "href": "slides/Chapter6.html#control-variates",
    "title": "Short Course on R Tools",
    "section": "Control Variates",
    "text": "Control Variates\n\nExplanation of control variates and how they reduce variance\nExample: Using control variates in Monte Carlo integration\n\n\n# Control variates example\nm &lt;- 10000\nx &lt;- runif(m)\ntheta.hat &lt;- mean(exp(-x)) - (mean(x) - 0.5)\ntheta.hat\n\n[1] 0.6304755",
    "crumbs": [
      "Slides",
      "CRAN submission"
    ]
  },
  {
    "objectID": "slides/Chapter6.html#antithetic-variables",
    "href": "slides/Chapter6.html#antithetic-variables",
    "title": "Short Course on R Tools",
    "section": "Antithetic Variables",
    "text": "Antithetic Variables\n\nExplanation of antithetic variables and how they reduce variance\nExample: Applying antithetic variables\n\n\n# Antithetic variables example\nu &lt;- runif(5000)\ntheta.hat &lt;- mean((exp(-u) + exp(-(1 - u))) / 2)\ntheta.hat\n\n[1] 0.632435\n\n1 - exp(-1)\n\n[1] 0.6321206",
    "crumbs": [
      "Slides",
      "CRAN submission"
    ]
  },
  {
    "objectID": "slides/Chapter4.html#key-points",
    "href": "slides/Chapter4.html#key-points",
    "title": "Short Course on R Tools",
    "section": "Key Points",
    "text": "Key Points\n\nclass(x) order\nNextMethod()\nOverloading + inheritance via class vectors\n\n??? note Demo: create print.myclass, show dispatch.",
    "crumbs": [
      "Slides",
      "OOP in R"
    ]
  },
  {
    "objectID": "computing/computing-cheatsheets.html",
    "href": "computing/computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://posit.co/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Short Course on R Tools - (SCoRT)",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the short course. Note that this schedule will be updated as we progress, and the timeline of topics and assignments might be updated throughout the course.\n\n\n\n\n\n\n\n\n\nWEEK\nDATE\nTOPIC\nMATERIALS\nCODE\nDUE\n\n\n\n\n1\nTue, Aug 26\n Develop your own professional R package\n📚Topic 1\nR👩‍💻\n\n\n\n\n\n\nThu, Aug 28\nEnhance performance with Rcpp (C++)\n📚Topic 2\nR👩‍💻\n\n\n\n\n\n\nFri, Aug 29\n\n\n\n\n\n\n📝 [HW 0]\n\n\n2\nTue, Sep 2\n Manage and collaborate via GitHub\n📚Topic 3\nR👩‍💻\n\n\n\n\n\n\nThu, Sep 4\n Object-Oriented Programming (OOP) in R\n📚Topic 4\nR Shiny👩‍💻\n\n\n\n\n\n\nFri, Sep 5\n\n\n\n\n\n\n📝 HW 1 at 11:50 pm\n\n\n3\nTue, Sep 9\n Create dynamic Shiny web applications\n📚Topic 5\nD2L✍️\n\n\n\n\n\n\nThu, Sep 11\n Navigate the CRAN submission process\n📚Topic 6\nR👩‍💻\n\n\n\n\n\n\nFri, Sep 12\n\n\n\n\n\n\n📝 HW 2 at 11:50 pm\n\n\n4\nTue, Sep 16\n Integrate Python in R using Reticulate\n📚Topic 7\nR👩‍💻\n\n\n\n\n\n\nThu, Sep 18\n Deep Learning in R\n📚Topic 8\nR Shiny👩‍💻\n\n\n\n\n\n\nFri, Sep 19\n\n\n\n\n\n\n📝 HW 3 at 11:50 pm",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio\nStat Calculator\nDistribution Calculator\n🔗 on dna\n🔗 StatCalc(JAMM)\n🔗 DistCalc\n\n\nAdvanced Texbooks\n🔗 R Package\n🔗 Advanced R by Hadley Wickham\n🔗 Quarto\n🔗 R Markdown\n🔗 ggplot2: Elegant Graphics for Data Analysis\n🔗 Fundamentals of Data Visualization\n🔗 Data Visualization: A Practical Introduction\n🔗 R for Data Science\n\n\nSome Package documentation\n🔗 ggplot2: ggplot2.tidyverse.org\n🔗 dplyr: dplyr.tidyverse.org\n🔗 tidyr: tidyr.tidyverse.org\n🔗 forcats: forcats.tidyverse.org\n🔗 stringr: stringr.tidyverse.org\n🔗 lubridate: lubridate.tidyverse.org\n🔗 readr: readr.tidyverse.org",
    "crumbs": [
      "Course information",
      "Useful links"
    ]
  }
]