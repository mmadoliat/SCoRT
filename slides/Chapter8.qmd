---
title: "Short Course on R Tools"
subtitle: "Deep Learning in R"
title-slide-attributes:
  data-background-image: mu-bg.png
  data-background-size: stretch
  data-slide-number: none
format:
  revealjs:
    transition: fade
    scrollable: true
---

# Outline

::: {.fragment .fade-up}
-   Introduction & Setup
-   Fundamentals of Neural Networks
-   Building MLPs for Classification & Regression
-   Convolutional Neural Networks (CNNs)
-   Recurrent Neural Networks (RNNs) & LSTM
-   Autoencoders & Unsupervised Learning
-   Model Evaluation & Tuning
-   Advanced Topics & Deployment
-   Hands-on Exercises
:::

# 1. Introduction & Environment Setup

-   **Why Deep Learning?** complex function approximation, feature engineering

-   **Keras in R**: high-level API for TensorFlow backend

-   **Installation**:

    ``` {.r}
    install.packages("keras")
    library(keras)
    install_keras()  # installs TensorFlow
    ```

-   **Project structure**: data/, scripts/, models/

??? note Demo environment check: `tensorflow::tf_config()`.

## Classical Programming vs Machine Learning {.smaller auto-animate="true"}

-   Deep learning is often presented as algorithms that ‚Äúwork like the brain‚Äù, that ‚Äúthink‚Äù or ‚Äúunderstand‚Äù.

. . . 

<div style="margin-top: -30px;"><center>[*Reality is however quite far from this dream*]{.text-red}</center></div>

. . .

-   AI: the effort to automate intellectual tasks normally performed by humans.

![](images/DLiR/classical-programming.png){.absolute top=210 left=80 width="400px"} 
<div style="margin-top: 90px;"></div>

. . .

-   ML: Could a computer surprise us? Rather than programmers crafting data-processing rules by hand, could a computer automatically learn these rules by looking at data?
![](images/DLiR/machine-learning.png){.absolute top=225 left=530 width="400px"} 
<div style="margin-top: -40px;"></div>

. . .

:::::: {.r-hstack style="margin-top: 1em;"}
::: {data-id="box1" auto-animate-delay="0" style="background: #2780e3; width: 200px; height: 150px; margin: 10px; display: flex; align-items: top; justify-content: center; color: white; font-size: 0.5em;"}
Artificial Intelligence
:::

::: {data-id="box2" auto-animate-delay="0.1" style="background: #3fb618; width: 200px; height: 150px; margin: 10px; display: flex; align-items: top; justify-content: center; color: white; font-size: 0.5em;"}
Machine learning
:::

::: {data-id="box3" auto-animate-delay="0.2" style="background: #e83e8c; width: 200px; height: 150px; margin: 10px; display: flex; align-items: top; justify-content: center; color: white; font-size: 0.5em;"}
Deep learning
:::
::::::

## Classical Programming vs Machine Learning {.smaller auto-animate="true"}

-   Deep learning is often presented as algorithms that ‚Äúwork like the brain‚Äù, that ‚Äúthink‚Äù or ‚Äúunderstand‚Äù.

<div style="margin-top: -30px;">&nbsp;</center></div>

-   AI: the effort to automate intellectual tasks normally performed by humans.

![](images/DLiR/classical-programming.png){.absolute top=210 left=80 width="400px"} 
<div style="margin-top: 90px;"></div>

-   ML: Could a computer surprise us? Rather than programmers crafting data-processing rules by hand, could a computer automatically learn these rules by looking at data?
![](images/DLiR/machine-learning.png){.absolute top=225 left=530 width="400px"} 
<div style="margin-top: -40px;"></div>

::::::: r-stack
:::::: {.r-stack style="margin-top: 1em;"}
::: {data-id="box1" style="background: #2780e3; width: 600px; height: 200px; border-radius: 200px; display: flex; align-items: top; justify-content: center; color: white; font-size: 0.5em;"}
Artificial Intelligence
:::

::: {data-id="box2" style="background: #3fb618; width: 430px; height: 130px; border-radius: 200px; display: flex; align-items: top; justify-content: center; color: white; font-size: 0.5em;"}
Machine learning
:::

::: {data-id="box3" style="background: #e83e8c; width: 260px; height: 60px; border-radius: 200px; display: flex; align-items: top; justify-content: center; color: white; font-size: 0.5em;"}
Deep learning
:::
::::::

![](images/DLiR/AI-ML-DL.png){.fragment width="750"}
:::::::

## Recipes of a Machine Learning Algorithm {.smaller auto-animate="true"}
::: incremental
-   Input data points, e.g.
![](images/DLiR/mse-1.png){.absolute bottom=0 left=300 width="400"}
    -   If the task is speech recognition, these data points could be sound files
    -   If the task is image tagging, they could be picture files

-   Examples of the expected output
![](images/DLiR/mse-2.png){.absolute bottom=0 left=300 width="400"}
    -   In a speech-recognition task, these could be transcripts of sound files
    -   In an image task, expected outputs could tags such as "dog", "cat", and so on

-   A way to measure whether the algorithm is doing a good job
![](images/DLiR/mse-3.png){.absolute bottom=0 left=300 width="400"}
    -   This is needed to determine the distance between the output and its expected output.
    -   The measurement is used as a feedback signal to adjust the way the algorithm works.
<div style="margin-top: -30px;">![](images/DLiR/mse-4.png){.absolute bottom=0 left=300 width="400"}</div>

:::

## Anatomy of a Neural Network {auto-animate="true"}
<div style="margin-top: -20px;"></div>
::: incremental
-   The [*input data*]{.text-red} and corresponding [*targets*]{.text-red}
![](images/DLiR/nn-1.png){.absolute bottom=0 left=200 width=500}

-   [*Layers*]{.text-red}, which are combined into a [*network* (or *model*)]{.text-red}
![](images/DLiR/nn-2.png){.absolute bottom=0 left=200 width=500}

-   The [*loss function*]{.text-red}, which provides feedback for learning
![](images/DLiR/nn-3.png){.absolute bottom=0 left=200 width=500}

-   The [*optimizer*]{.text-red}, which determines how learning proceeds
![](images/DLiR/nn-4.png){.absolute bottom=0 left=200 width=500}
:::

## LeNet-5: a pioneering 7-level CNN {auto-animate="true" .smaller}
[<img src="images/DLiR/LeNet-5_architecture.png" style="opacity: 0.10;">]{.absolute top=75 left=0}

::: incremental
-   The first successful practical application of neural nets came in 1989 from Bell Labs, when [*Yann LeCun*]{.text-red} combined the earlier ideas of convolutional neural networks and backpropagation, and applied them to the problem of classifying handwritten digits.

-   The resulting network, dubbed LeNet, was used by the USPS in the 1990s to automate the reading of ZIP codes on mail envelopes.

-   LeNet-5 was applied by several banks to recognize hand-written numbers on checks digitized in 32x32 pixel images.
:::

<center>![](images/DLiR/cnn.gif){width=550}</center>

## Why 30+ Years gap? {auto-animate="true"}
[<img src="images/DLiR/imagenet-1.png" style="opacity: 0.10" width=1200>]{.absolute top=75 left=0}

::: incremental
-   In 2011, Dan Ciresan from IDSIA (Switzerland) began to win academic image-classification competitions with GPU-trained deep neural networks

-   in 2012, a team led by Alex Krizhevsky and advised by [*Geoffrey Hinton*]{.text-red} was able to achieve a top-five accuracy of 83.6%--a significant breakthrough (in 2011 it was only 74.3%).
![](images/DLiR/imagenet-2.png){.absolute bottom=0 right=0 width=350 height=300}

-   Three forces are driving advances in ML:
    -   Hardware
    -   Datasets and benchmarks
    -   Algorithmic advances
:::

## VGG16‚ÄìCNN for Classification and Detection {auto-animate="true" .smaller}
[<img src="images/DLiR/VGG16-1.png" style="opacity: 0.10" width="1500">]{.absolute top=0 right=0}

::: incremental
-   VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford.

-   The model achieves 92.7% top-5 test accuracy in ImageNet. It was one of the famous model submitted to ILSVRC-2014.

-   It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3√ó3 kernel-sized filters one after another.

-   VGG16 was trained for weeks using NVIDIA Titan Black GPU‚Äôs.
![](images/DLiR/VGG16-2.png){.absolute bottom=0 left=250 width=500}
:::

# 2. Fundamentals of Neural Networks {auto-animate="true"}

-   **Perceptron**: basic neuron ‚Üí activation(input \* weight + bias)

-   **Layers**: Dense layers, activation functions (`relu`, `sigmoid`, `softmax`)

-   **Forward & backward pass**: feedforward, gradient descent

::: shrink-code
``` {.r}
model <- keras_model_sequential(input_shape = c(784)) %>%
  layer_dense(units = 32, activation = 'relu') %>%
  layer_dense(units = 10, activation = 'softmax')
```
:::

??? note Visualize network architecture with `plot_model()`.

[üîó Launch R](http://tinyurl.com/dna-Rstudio){target=_blank}

## Neural Network ‚Äì Parameters - Activation Func. {auto-animate="true"}

![](images/DLiR/nn-01.png){.absolute bottom=0 left=0 width=500}

. . .

<div style="margin-top: 55px;"></div>
<span style="padding-left: 3.5em;">[*A Neural Network*]{.text-red}</span>

. . .

![](images/DLiR/nn-02.png){.absolute bottom=0 left=0 width=500}

. . . 

![](images/DLiR/nn-03.png){.absolute bottom=0 left=0 width=500}

. . .

![](images/DLiR/af-1.png){.absolute bottom=100 right=0 width=500}

. . . 

<div style="margin-top: -55px;"></div>
<span style="padding-left: 17.5em;">[*Activation Function*]{.text-red}</span>

. . .

![](images/DLiR/af-2.png){.absolute bottom=100 right=0 width=500}

## Linear Activation function

![](images/DLiR/nn01.png){.absolute bottom=0 right=0 width=400}

. . .

![](images/DLiR/nn02.png){.absolute bottom=0 right=0 width=400}

-   $Z=\color{green}{W_1}X+\color{lightblue}{b_1}$
<div style="margin-top: 40px;"></div>

. . .

![](images/DLiR/nn03.png){.absolute bottom=0 right=0 width=400}

-   $Y=\color{red}{W_2}Z+\color{blue}{b_2}$

. . .

-   $Y=\color{red}{W_2}\{\color{green}{W_1}X+\color{lightblue}{b_1}\}+\color{blue}{b_2}$

. . .

-   $Y=\{\color{red}{W_2}\color{green}{W_1}\}X+\{\color{red}{W_2}\color{lightblue}{b_1}+\color{blue}{b_2}\}$
<div style="margin-top: 40px;"></div>

. . .

![](images/DLiR/nn04.png){.absolute bottom=0 right=0 width=400 height=580}

-   $Y=\color{red}{\mathbf{W}^*}X+\color{blue}{\mathbf{b}^*}$

. . .

<span style="padding-left: 3.5em;">[**Hidden Layers Disappears**]{.text-red}</span>

## What is TensorFlow?

::: incremental
-   You define the graph in R
-   Graph is compiled and optimized
-   Graph is executed on devices
-   Nodes represent computations
-   Data (tensors) flows between them
:::

&nbsp; [<img src="images/DLiR/tensors_flowing.gif" width=420>]{.absolute bottom=0 right=50 width=420}

## Why TensorFlow in R? 

::: incremental
-   Hardware independent
    -   CPU (via Eigen and BLAS)
    -   GPU (via CUDA and cuDNN)
    -   TPU (Tensor Processing Unit)
-   Supports automatic differentiation
-   Distributed execution and large datasets
-   Very general built-in optimization algorithms (SGD, Adam) 
that don't require that all data is in RAM
-   It can be deployed with a low-latency C++ runtime
-   R has a lot to offer as an interface language for TensorFlow

:::

&nbsp; [<img src="images/DLiR/tensors_flowing.gif" style="opacity: 0.15;" width=420>]{.absolute bottom=0 right=50 width=420}

## Real-world examples of data tensors {auto-animate="true"  .smaller}

[<img src="images/DLiR/tensors_flowing.gif" style="opacity: 0.05;" width=420>]{.absolute bottom=0 right=50 width=420}

-   2D tensors
    -   Vector data‚Äî(samples, features)
![](images/DLiR/tensor-2d.png){.absolute top=60 left=475 width=150}
![](images/DLiR/tensor2D.png){.absolute top=50 right=0 width=400}

. . .

-   3D tensors
    -   Grayscale Images‚Äî(samples, height, width) 
    - Time-series data or sequence data‚Äî(samples, timesteps, features)

. . .

![](images/DLiR/tensor-3d.png){.absolute top=290 left=475 width=150}
![](images/DLiR/tensor3D.png){.absolute top=300 right=0 width=400}

. . . 

<div style="margin-top: 100px;"></div>
-   4D tensors
    -   Color Images‚Äî(samples, height, width, channels) 

. . .

![](images/DLiR/tensor-4d.png){.absolute top=350 left=150 width=75}
![](images/DLiR/tensor4D.png){.absolute top=450 right=0 width=275}

. . .

<div style="margin-top: -20px;"></div>
-   5D tensors
    -   Video‚Äî(samples, frames, height, width, channels)

. . .

![](images/DLiR/tensor-5d.png){.absolute bottom=0 right=300 width=125}

## Installing Keras {.small}

&nbsp; [<img src="images/DLiR/tensors_flowing.gif" style="opacity: 0.05;" width=420>]{.absolute bottom=0 right=50 width=420}
<div style="margin-top: -20px;"></div>
-   First, install the keras R package:
``` {.r}
remotes::install_github("rstudio/keras3");    # OR
Install.packages("keras3")
```

. . .

-   To install both the core [Keras](https://keras.rstudio.com/) library as well as the [TensorFlow](https://www.tensorflow.org/) backend
``` {.r}
library(keras3)
keras3::install_keras(backend = "tensorflow")
```

. . .

-   You need Python installed before installing TensorFlow
    -   [Anaconda](https://www.anaconda.com/) (Python distribution), a free and open-source software

. . .

<div style="margin-top: -20px;"></div>
-   You can install TensorFlow with GPU support
    -   NVIDIA¬Æ drivers, 
    -   CUDA Toolkit v9.0, and 
    -   cuDNN v7.0
    
<div style="margin-top: -20px;"></div>
are needed: [https://tensorflow.rstudio.com/tools/local_gpu.html](https://tensorflow.rstudio.com/tools/local_gpu.html)


## Developing a Deep NN with Keras {.small}

&nbsp; [<img src="images/DLiR/tensors_flowing.gif" style="opacity: 0.05;" width=420>]{.absolute bottom=0 right=50 width=420}
<div style="margin-top: -20px;"></div>
-   Step 1 - Define your training data: 
    -   input tensors and target tensors.

. . .

-   Step 2 - Define a network of layers (or model) 
    -   that maps your inputs to your targets.

. . .

-   Step 3 - Configure the learning process by choosing 
    -   a loss function, 
    -   an optimizer, 
    -   and some metrics to monitor.

. . .

-   Step 4 - Iterate on your training data by calling the 
    -   **fit()** method of your model.

# 3. Multilayer Perceptrons (MLPs)

## Keras: Step 1 ‚Äì Data preprocessing {.small}
&nbsp; [<img src="images/DLiR/tensors_flowing.gif" style="opacity: 0.05;" width=420>]{.absolute bottom=0 right=50 width=420}
<div style="margin-top: -40px;"></div>
::: shrink-code
``` {.r code-line-numbers="1|3-4|6-8|9-10|12-14" height="100"}
library(keras)

# Load MNIST (Modified National Institute of Standards and Technology) 
images datasets c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()

# Flatten images and transform RGB values into [0,1] range 
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
x_train <- x_train / 255
x_test <- x_test / 255

# Convert class vectors to binary class matrices
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
```
:::

![](images/DLiR/step1.png){.absolute bottom=0 left=50 width=950}

## Classification on MNIST

``` r
model %>% compile(
  optimizer = 'rmsprop',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy')
)
history <- model %>% fit(
  x_train, y_train,
  epochs = 10, batch_size = 128,
  validation_split = 0.2
)
```

-   **Data preprocessing**: normalization, one-hot encoding

-   **Callbacks**: EarlyStopping, ModelCheckpoint

??? note Show training curves: `plot(history)`.

# 4. Convolutional Neural Networks (CNNs)

-   **Concepts**: filters, pooling, feature maps

-   **Example**:

``` r
cnn <- keras_model_sequential() %>%
  layer_conv_2d(filters=32, kernel_size=c(3,3), activation='relu', input_shape=c(28,28,1)) %>%
  layer_max_pooling_2d(pool_size=c(2,2)) %>%
  layer_conv_2d(filters=64, kernel_size=c(3,3), activation='relu') %>%
  layer_max_pooling_2d(pool_size=c(2,2)) %>%
  layer_flatten() %>%
  layer_dense(units=64, activation='relu') %>%
  layer_dense(units=10, activation='softmax')
```

-   **Image augmentation**: `image_data_generator()`

??? note Demo augmenting and fitting on CIFAR-10 subset.

# 5. Recurrent Neural Networks & LSTM

-   **RNN basics**: sequence data, time steps

-   **LSTM**: handling long-term dependencies

``` r
rnn <- keras_model_sequential() %>%
  layer_lstm(units=128, input_shape=c(timesteps, features)) %>%
  layer_dense(units=1, activation='sigmoid')
```

-   **Use case**: sentiment analysis, text generation

??? note Show example on IMDB dataset: `dataset_imdb()`.

# 6. Autoencoders & Unsupervised Learning

-   **Architecture**: encoder ‚áÑ bottleneck ‚áÑ decoder

``` r
ae <- keras_model_sequential() %>%
  layer_dense(units=64, activation='relu', input_shape=c(784)) %>%
  layer_dense(units=32, activation='relu') %>%
  layer_dense(units=64, activation='relu') %>%
  layer_dense(units=784, activation='sigmoid')
```

-   **Applications**: dimensionality reduction, denoising

??? note Demo training on noisy MNIST.

# 7. Model Evaluation & Hyperparameter Tuning

-   **Metrics**: accuracy, precision/recall, ROC-AUC

-   **Plots**: confusion matrix, learning curves

-   **Tuning**: `tfruns`, `keras_tuner`

-   **K-fold CV**: manual splits or `rsample`

??? note Illustrate hyperband tuning example.

# 8. Advanced Topics & Deployment

-   **Transfer Learning**: `application_resnet50()`, fine-tuning

-   **Custom layers & callbacks**

-   **Model saving/loading**: `save_model_hdf5()`, `load_model_hdf5()`

-   **Deployment**: Plumber API, TensorFlow Serving, Shiny integration

??? note Example: wrap model in Plumber endpoint.

# 9. Hands-on Exercises (30 min)

1.  Build and train a CNN on Fashion MNIST

2.  Implement an LSTM for sequence prediction (e.g., sine wave)

3.  Create an autoencoder for dimensionality reduction and visualize embeddings

??? note Encourage pair work and code sharing.

# Resources & Further Reading

-   Book: *Deep Learning with R* by Francois Chollet & J.J. Allaire

-   Keras docs: https://keras.rstudio.com/

-   TensorFlow for R: https://tensorflow.rstudio.com/

-   Tutorials: https://www.coursera.org/learn/deep-learning

??? note Provide links for reference.
